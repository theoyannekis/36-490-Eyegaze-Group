title: "eyegaze random forest"
output: 
  html_document:
    toc:  true
    toc_float:  true
    code_folding:  show
---

```{r, message = F, error = F}
library(glmnet)
```

```{r}
eyegaze <- read.csv("Eyetracking_Data.csv",na.string=c("999","999.00","#NULL!"),stringsAsFactors = FALSE)
eyegaze <- na.omit(eyegaze)
eyegaze$ID <- NULL
eyegaze$DOT <- NULL
eyegaze$DOB <- NULL
eyegaze$Comp_E_Percent <- NULL
eyegaze$Comp_E_Total <- NULL
eyegaze$Comp_Percent <- NULL
eyegaze$Comp_Total <- NULL
eyegaze$Comp_S_Total <- NULL
eyegaze$Comp_S_Percent <- NULL
```

```{r}
set.seed(100)
train.index <- sample(1:nrow(eyegaze), 0.7*nrow(eyegaze))
train <- eyegaze[train.index, ]
test <- eyegaze [-train.index, ]

x <- model.matrix(CompDiff~., train)[,-1]
y <- train$CompDiff

x.test <- model.matrix(CompDiff~., test)[,-1]
y.test <- test$CompDiff

fit.lasso <- glmnet(x, y,family="gaussian", alpha=1)
fit.ridge <- glmnet(x, y,family="gaussian", alpha=0)
fit.elnet <- glmnet(x, y,family="gaussian", alpha=.5)

```


```{r}
fit.lasso.cv <- cv.glmnet(x, y, type.measure="mse", alpha=1, 
                          family="gaussian")
fit.ridge.cv <- cv.glmnet(x, y, type.measure="mse", alpha=0,
                          family="gaussian")
fit.elnet.cv <- cv.glmnet(x, y, type.measure="mse", alpha=.5,
                          family="gaussian")

```


```{r}
for (i in 0:10) {
    assign(paste("fit", i, sep=""), cv.glmnet(x, y, type.measure="mse", 
                                              alpha=i/10,family="gaussian"))
}
```

```{r}
# Plot solution paths:
par(mfrow=c(3,2))
# For plotting options, type '?plot.glmnet' in R console
plot(fit.lasso, xvar="lambda")
plot(fit10, main="LASSO")

plot(fit.ridge, xvar="lambda")
plot(fit0, main="Ridge")

plot(fit.elnet, xvar="lambda")
plot(fit5, main="Elastic Net")
```

```{r}
yhat0 <- predict(fit0, s=fit0$lambda.1se, newx=x.test)
yhat1 <- predict(fit1, s=fit1$lambda.1se, newx=x.test)
yhat2 <- predict(fit2, s=fit2$lambda.1se, newx=x.test)
yhat3 <- predict(fit3, s=fit3$lambda.1se, newx=x.test)
yhat4 <- predict(fit4, s=fit4$lambda.1se, newx=x.test)
yhat5 <- predict(fit5, s=fit5$lambda.1se, newx=x.test)
yhat6 <- predict(fit6, s=fit6$lambda.1se, newx=x.test)
yhat7 <- predict(fit7, s=fit7$lambda.1se, newx=x.test)
yhat8 <- predict(fit8, s=fit8$lambda.1se, newx=x.test)
yhat9 <- predict(fit9, s=fit9$lambda.1se, newx=x.test)
yhat10 <- predict(fit10, s=fit10$lambda.1se, newx=x.test)

mse0 <- mean((y.test - yhat0)^2)
mse1 <- mean((y.test - yhat1)^2)
mse2 <- mean((y.test - yhat2)^2)
mse3 <- mean((y.test - yhat3)^2)
mse4 <- mean((y.test - yhat4)^2)
mse5 <- mean((y.test - yhat5)^2)
mse6 <- mean((y.test - yhat6)^2)
mse7 <- mean((y.test - yhat7)^2)
mse8 <- mean((y.test - yhat8)^2)
mse9 <- mean((y.test - yhat9)^2)
mse10 <- mean((y.test - yhat10)^2)

for(i in 1:10){
  name = paste("mse",i,sep="")
  print(eval(as.name(name)))
}
```
```{r}
bestlam = fit.lasso.cv$lambda.min
predict(fit.lasso, type = 'coefficients', s = bestlam)
bestlam = fit.ridge.cv$lambda.min
predict(fit.ridge, type = 'coefficients', s = bestlam)
bestlam = fit.elnet.cv$lambda.min
predict(fit.elnet, type = 'coefficients', s = bestlam)
coef(fit.lasso)
```



